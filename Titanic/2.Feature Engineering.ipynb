{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string \n",
    "from patsy import dmatrices\n",
    "from operator import itemgetter\n",
    "#model \n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, GradientBoostingRegressor \n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import preprocessing\n",
    "import xgboost as xgb\n",
    "#evaluation metrics \n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.externals import joblib\n",
    "#visulisation \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/train.csv')\n",
    "test_df = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
       "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df['Survived'] = 0\n",
    "all_df = train_df.append(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 12)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering - category features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform the category features \n",
    "1. Fare\n",
    "2. Pclass\n",
    "3. Family Size\n",
    "4. Age group\n",
    "5. Name length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def drop_col_not_req(df, cols):\n",
    "    df.drop(cols, axis = 1, inplace = True)\n",
    "\n",
    "def fare_category(fare):\n",
    "    if (fare <= 4):\n",
    "        return 'Very_Low_Fare'\n",
    "    elif (fare <= 10):\n",
    "        return 'Low_Fare'\n",
    "    elif (fare <= 30):\n",
    "        return 'Med_Fare'\n",
    "    elif (fare <= 45):\n",
    "        return 'High_Fare'\n",
    "    else:\n",
    "        return 'Very_High_Fare'\n",
    "\n",
    "def pclass_fare_category(df, Pclass_1_mean_fare, Pclass_2_mean_fare, Pclass_3_mean_fare):\n",
    "    if (df['Pclass'] == 1):\n",
    "        if (df['Fare'] <= Pclass_1_mean_fare):\n",
    "            return 'Pclass_1_Low_Fare'\n",
    "        else:\n",
    "            return 'Pclass_1_High_Fare'\n",
    "    elif (df['Pclass'] == 2):\n",
    "        if (df['Fare'] <= Pclass_2_mean_fare):\n",
    "            return 'Pclass_2_Low_Fare'\n",
    "        else:\n",
    "            return 'Pclass_2_High_Fare'\n",
    "    elif (df['Pclass'] == 3):\n",
    "        if (df['Fare'] <= Pclass_3_mean_fare):\n",
    "            return 'Pclass_3_Low_Fare'\n",
    "        else:\n",
    "            return 'Pclass_3_High_Fare'\n",
    "\n",
    "def family_size_category(family_size):\n",
    "    if (family_size <= 1):\n",
    "        return 'Single'\n",
    "    elif (family_size <= 3):\n",
    "        return 'Small_Family'\n",
    "    else:\n",
    "        return 'Large_Family'\n",
    "\n",
    "def age_group_cat(age):\n",
    "    if (age <= 1):\n",
    "        return 'Baby'\n",
    "    if (age <= 4):\n",
    "        return 'Toddler'\n",
    "    elif(age <= 12):\n",
    "        return 'Child'\n",
    "    elif (age <= 19):\n",
    "        return 'Teenager'\n",
    "    elif (age <= 30):\n",
    "        return 'Adult'\n",
    "    elif (age <= 50):\n",
    "        return 'Middle_Aged'\n",
    "    elif(age < 60):\n",
    "        return 'Senior_Citizen'\n",
    "    else:\n",
    "        return 'Old'\n",
    "\n",
    "def name_len_category(name_len):\n",
    "    if (name_len <= 19):\n",
    "        return 'Very_Short_Name'\n",
    "    elif (name_len <= 28):\n",
    "        return 'Short_Name'\n",
    "    elif (name_len <= 45):\n",
    "        return 'Medium_Name'\n",
    "    else:\n",
    "        return 'Long_Name'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Handling missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use **GradientBoostingRegressor** and **LinearRegression** to fill the missing value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fill_missing_age(missing_age_train, missing_age_test):\n",
    "    missing_age_X_train = missing_age_train.drop(['Age'], axis = 1)\n",
    "    missing_age_y_train = missing_age_train['Age']\n",
    "    missing_age_X_test = missing_age_test.drop(['Age'], axis = 1)\n",
    "    \n",
    "    #gridsearch for best parameters fit for GradientBoostingRegressor\n",
    "    gbm_reg = GradientBoostingRegressor(random_state = 42)\n",
    "    gbm_reg_param_grid = {'n_estimators': [2000], 'max_depth': [3], 'learning_rate': [0.01], 'max_features': [3]}\n",
    "    gbm_reg_grid = GridSearchCV(gbm_reg, gbm_reg_param_grid, cv = 10, n_jobs = 25, verbose = 1, scoring = 'neg_mean_squared_error')\n",
    "    gbm_reg_grid.fit(missing_age_X_train, missing_age_y_train)\n",
    "    \n",
    "    print(\"Age feature Best GB Params: \" + str(gbm_reg_grid.best_params_))\n",
    "    print(\"Age feature Best GB Score: \" + str(gbm_reg_grid.best_score_))\n",
    "    print(\"GB Train Error for 'Age' Feature Regressor: \" + str(gbm_reg_grid.score(missing_age_X_train, missing_age_y_train)))\n",
    "    \n",
    "    missing_age_test['Age_GB'] = gbm_reg_grid.predict(missing_age_X_test)\n",
    "    print(missing_age_test['Age_GB'][:4])\n",
    "    \n",
    "    #gridsearch for best parameters fit for LinearRegression\n",
    "    lrf_reg = LinearRegression()\n",
    "    lrf_reg_param_grid = {'fit_intercept': [True], 'normalize': [True]}\n",
    "    lrf_reg_grid = GridSearchCV(lrf_reg, lrf_reg_param_grid, cv = 10, n_jobs = 25, verbose = 1, scoring = 'neg_mean_squared_error')\n",
    "    lrf_reg_grid.fit(missing_age_X_train, missing_age_y_train)\n",
    "    \n",
    "    print(\"Age feature Best LR Params: \" + str(lrf_reg_grid.best_params_))\n",
    "    print(\"Age feature Best LR Score: \" + str(lrf_reg_grid.best_score_))\n",
    "    print(\"LR Train Error for 'Age' Feature Regressor: \" + str(lrf_reg_grid.score(missing_age_X_train, missing_age_y_train)))\n",
    "    \n",
    "    missing_age_test['Age_LRF'] = lrf_reg_grid.predict(missing_age_X_test)\n",
    "    print(missing_age_test['Age_LRF'][:4])\n",
    "    \n",
    "    missing_age_test['Age'] = missing_age_test[['Age_GB', 'Age_LRF']].mean(axis = 1)\n",
    "\n",
    "    print(missing_age_test['Age'][:4])\n",
    "    drop_col_not_req(missing_age_test, ['Age_GB', 'Age_LRF'])\n",
    "\n",
    "    return missing_age_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Pick top 'N' features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick up top 'N' features in different ensemble models (**RandomForestClassifier**, **AdaBoostClassifier**, and **ExtraTreesClassifier**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_top_n_features(titanic_train_data_X, titanic_train_data_y, top_n_features):\n",
    "    #random forest \n",
    "    rf_est = RandomForestClassifier(random_state = 42)\n",
    "    rf_param_grid = {'n_estimators' : [500], 'min_samples_split':[2, 3], 'max_depth':[20]}\n",
    "    rf_grid =GridSearchCV(rf_est, rf_param_grid, n_jobs = 25, cv = 10, verbose = 1)\n",
    "    rf_grid.fit(titanic_train_data_X, titanic_train_data_y)\n",
    "    \n",
    "    print(\"Top N Features Best RF Params: \" + str(rf_grid.best_params_))\n",
    "    print(\"Top N Features Best RF Score: \" + str(rf_grid.best_score_))\n",
    "    print(\"Top N Features RF Train Error: \" + str(rf_grid.score(titanic_train_data_X, titanic_train_data_y)))\n",
    "\n",
    "    feature_imp_sorted_rf = pd.DataFrame({'feature': list(titanic_train_data_X), \n",
    "                                          'importance': rf_grid.best_estimator_.feature_importances_}).sort_values('importance', ascending = False)\n",
    "    features_top_n_rf = feature_imp_sorted_rf.head(top_n_features)['feature']\n",
    "    print(\"Sample 25 Features from RF Classifier:\")\n",
    "    print(str(features_top_n_rf[:25]))\n",
    "    \n",
    "    #ada boost \n",
    "    ada_est = AdaBoostClassifier(random_state = 42)\n",
    "    ada_param_grid = {'n_estimators' : [500], 'learning_rate': [0.5, 0.6]}\n",
    "    ada_grid = GridSearchCV(ada_est, ada_param_grid, n_jobs = 25, cv = 10, verbose = 1)\n",
    "    ada_grid.fit(titanic_train_data_X, titanic_train_data_y)\n",
    "    \n",
    "    print(\"Top N Features Best Ada Params: \" + str(ada_grid.best_params_))\n",
    "    print(\"Top N Features Best Ada Score: \" + str(ada_grid.best_score_))\n",
    "    print(\"Top N Features Ada Train Error: \" + str(ada_grid.score(titanic_train_data_X, titanic_train_data_y)))\n",
    "    \n",
    "    feature_imp_sorted_ada = pd.DataFrame({'feature': list(titanic_train_data_X), 'importance': ada_grid.best_estimator_.feature_importances_}).sort_values('importance', ascending = False)\n",
    "    features_top_n_ada = feature_imp_sorted_ada.head(top_n_features)['feature']\n",
    "    print(\"Sample 25 Features from Ada Classifier:\")\n",
    "    print(str(features_top_n_ada[:25]))\n",
    "    \n",
    "    #extra tree \n",
    "    et_est = ExtraTreesClassifier(random_state = 42)\n",
    "    et_param_grid = {'n_estimators' : [500], 'min_samples_split':[3, 4], 'max_depth':[15]}\n",
    "    et_grid = GridSearchCV(et_est, et_param_grid, n_jobs = 25, cv = 10, verbose = 1)\n",
    "    et_grid.fit(titanic_train_data_X, titanic_train_data_y)\n",
    "    \n",
    "    print(\"Top N Features Best ET Params: \" + str(et_grid.best_params_))\n",
    "    print(\"Top N Features Best ET Score: \" + str(et_grid.best_score_))\n",
    "    print(\"Top N Features ET Train Error: \" + str(et_grid.score(titanic_train_data_X, titanic_train_data_y)))\n",
    "    \n",
    "    feature_imp_sorted_et = pd.DataFrame({'feature': list(titanic_train_data_X), 'importance': et_grid.best_estimator_.feature_importances_}).sort_values('importance', ascending = False)\n",
    "    features_top_n_et = feature_imp_sorted_et.head(top_n_features)['feature']\n",
    "    print(\"Sample 25 Features from ET Classifier:\")\n",
    "    print(str(features_top_n_et[:25]))\n",
    "    \n",
    "    #### Merge top_n_features from all three models\n",
    "    features_top_n = pd.concat([features_top_n_rf, features_top_n_ada, features_top_n_et], ignore_index = True).drop_duplicates()\n",
    "    \n",
    "    return features_top_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Creating Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Embarked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survived  Embarked\n",
      "0         C           177\n",
      "          Q            93\n",
      "          S           697\n",
      "1         C            93\n",
      "          Q            30\n",
      "          S           217\n",
      "Name: Survived, dtype: int64\n",
      "Embarked\n",
      "S    914\n",
      "C    270\n",
      "Q    123\n",
      "Name: PassengerId, dtype: int64\n",
      "Embarked\n",
      "C    62.336267\n",
      "S    27.418824\n",
      "Q    12.409012\n",
      "Name: Fare, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(all_df.groupby(['Survived', 'Embarked'])['Survived'].count())\n",
    "print(all_df['PassengerId'].groupby(by = all_df['Embarked']).count().sort_values(ascending = False))\n",
    "print(all_df['Fare'].groupby(by = all_df['Embarked']).mean().sort_values(ascending = False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Name</th>\n",
       "      <th>Parch</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>113803</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age Cabin Embarked     Fare  \\\n",
       "0  22.0   NaN        S   7.2500   \n",
       "1  38.0   C85        C  71.2833   \n",
       "2  26.0   NaN        S   7.9250   \n",
       "3  35.0  C123        S  53.1000   \n",
       "4  35.0   NaN        S   8.0500   \n",
       "\n",
       "                                                Name  Parch  PassengerId  \\\n",
       "0                            Braund, Mr. Owen Harris      0            1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...      0            2   \n",
       "2                             Heikkinen, Miss. Laina      0            3   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)      0            4   \n",
       "4                           Allen, Mr. William Henry      0            5   \n",
       "\n",
       "   Pclass     Sex  SibSp  Survived            Ticket  Embarked_C  Embarked_Q  \\\n",
       "0       3    male      1         0         A/5 21171           0           0   \n",
       "1       1  female      1         1          PC 17599           1           0   \n",
       "2       3  female      0         1  STON/O2. 3101282           0           0   \n",
       "3       1  female      1         1            113803           0           0   \n",
       "4       3    male      0         0            373450           0           0   \n",
       "\n",
       "   Embarked_S  \n",
       "0           1  \n",
       "1           0  \n",
       "2           1  \n",
       "3           1  \n",
       "4           1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if (all_df['Embarked'].isnull().sum() != 0):\n",
    "    all_df['Embarked'].fillna(all_df['Embarked'].mode().iloc[0], inplace=True)\n",
    "\n",
    "emb_dummies_df = pd.get_dummies(all_df['Embarked'],\n",
    "                                prefix = all_df[['Embarked']].columns[0])\n",
    "all_df = pd.concat([all_df, emb_dummies_df], axis = 1)\n",
    "all_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Sex "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Name</th>\n",
       "      <th>Parch</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age Cabin Embarked     Fare  \\\n",
       "0  22.0   NaN        S   7.2500   \n",
       "1  38.0   C85        C  71.2833   \n",
       "2  26.0   NaN        S   7.9250   \n",
       "\n",
       "                                                Name  Parch  PassengerId  \\\n",
       "0                            Braund, Mr. Owen Harris      0            1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...      0            2   \n",
       "2                             Heikkinen, Miss. Laina      0            3   \n",
       "\n",
       "   Pclass     Sex  SibSp  Survived            Ticket  Embarked_C  Embarked_Q  \\\n",
       "0       3    male      1         0         A/5 21171           0           0   \n",
       "1       1  female      1         1          PC 17599           1           0   \n",
       "2       3  female      0         1  STON/O2. 3101282           0           0   \n",
       "\n",
       "   Embarked_S  Sex_female  Sex_male  \n",
       "0           1           0         1  \n",
       "1           0           1         0  \n",
       "2           1           1         0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sex_dummies_df = pd.get_dummies(all_df['Sex'],\n",
    "                                prefix = all_df[['Sex']].columns[0])\n",
    "all_df = pd.concat([all_df, sex_dummies_df], axis = 1)\n",
    "all_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Name Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mr' 'Mrs' 'Miss' 'Master' 'Don' 'Rev' 'Dr' 'Mme' 'Ms' 'Major' 'Lady'\n",
      " 'Sir' 'Mlle' 'Col' 'Capt' 'the Countess' 'Jonkheer' 'Dona']\n",
      "Title\n",
      "Mr              757\n",
      "Miss            260\n",
      "Mrs             197\n",
      "Master           61\n",
      "Dr                8\n",
      "Rev               8\n",
      "Col               4\n",
      "Ms                2\n",
      "Mlle              2\n",
      "Major             2\n",
      "Don               1\n",
      "Dona              1\n",
      "the Countess      1\n",
      "Jonkheer          1\n",
      "Lady              1\n",
      "Sir               1\n",
      "Mme               1\n",
      "Capt              1\n",
      "Name: Title, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:1: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "all_df['Title'] = all_df['Name'].str.extract('.+,(.+)').str.extract('^(.+?)\\.').str.strip()\n",
    "print(all_df['Title'].unique())\n",
    "print(all_df['Title'].groupby(by = all_df['Title']).count().sort_values(ascending = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "title_Dict = {}\n",
    "title_Dict.update(dict.fromkeys([\"Capt\", \"Col\", \"Major\", \"Dr\", \"Rev\"], \"Officer\"))\n",
    "title_Dict.update(dict.fromkeys([\"Jonkheer\", \"Don\", \"Sir\", \"the Countess\", \"Dona\", \"Lady\"], \"Royalty\"))\n",
    "title_Dict.update(dict.fromkeys([\"Mme\", \"Ms\", \"Mrs\"], \"Mrs\"))\n",
    "title_Dict.update(dict.fromkeys([\"Mlle\", \"Miss\"], \"Miss\"))\n",
    "title_Dict.update(dict.fromkeys([\"Mr\", \"Ms\"], \"Mr\"))\n",
    "title_Dict.update(dict.fromkeys([\"Master\"], \"Master\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title\n",
      "Mr         759\n",
      "Miss       262\n",
      "Mrs        198\n",
      "Master      61\n",
      "Officer     23\n",
      "Royalty      6\n",
      "Name: Title, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "all_df['Title'] = all_df['Title'].map(title_Dict)\n",
    "print(all_df['Title'].groupby(by = all_df['Title']).count().sort_values(ascending = False))\n",
    "\n",
    "title_dummies_df = pd.get_dummies(all_df['Title'],\n",
    "                                prefix = all_df[['Title']].columns[0])\n",
    "all_df = pd.concat([all_df, title_dummies_df], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Name length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name_Length\n",
      "25    83\n",
      "19    82\n",
      "18    75\n",
      "26    73\n",
      "27    70\n",
      "Name: Name_Length, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "all_df['Name_Length'] = all_df['Name'].str.len()\n",
    "print(all_df['Name_Length'].groupby(by = all_df['Name_Length']).count().sort_values(ascending = False)[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name_Length_Category\n",
      "Short_Name         592\n",
      "Medium_Name        337\n",
      "Very_Short_Name    292\n",
      "Long_Name           88\n",
      "Name: Name_Length_Category, dtype: int64\n",
      "                      Name_Length_Category  Survived\n",
      "Name_Length_Category              1.000000 -0.209793\n",
      "Survived                         -0.209793  1.000000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Name</th>\n",
       "      <th>Parch</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>...</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Officer</th>\n",
       "      <th>Title_Royalty</th>\n",
       "      <th>Name_Length</th>\n",
       "      <th>Name_Length_Category</th>\n",
       "      <th>Name_Length_Category_0</th>\n",
       "      <th>Name_Length_Category_1</th>\n",
       "      <th>Name_Length_Category_2</th>\n",
       "      <th>Name_Length_Category_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age Cabin Embarked     Fare  \\\n",
       "0  22.0   NaN        S   7.2500   \n",
       "1  38.0   C85        C  71.2833   \n",
       "2  26.0   NaN        S   7.9250   \n",
       "\n",
       "                                                Name  Parch  PassengerId  \\\n",
       "0                            Braund, Mr. Owen Harris      0            1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...      0            2   \n",
       "2                             Heikkinen, Miss. Laina      0            3   \n",
       "\n",
       "   Pclass     Sex  SibSp           ...            Title_Mr Title_Mrs  \\\n",
       "0       3    male      1           ...                   1         0   \n",
       "1       1  female      1           ...                   0         1   \n",
       "2       3  female      0           ...                   0         0   \n",
       "\n",
       "   Title_Officer  Title_Royalty  Name_Length  Name_Length_Category  \\\n",
       "0              0              0           23                     2   \n",
       "1              0              0           51                     0   \n",
       "2              0              0           22                     2   \n",
       "\n",
       "   Name_Length_Category_0 Name_Length_Category_1  Name_Length_Category_2  \\\n",
       "0                       0                      0                       1   \n",
       "1                       1                      0                       0   \n",
       "2                       0                      0                       1   \n",
       "\n",
       "   Name_Length_Category_4  \n",
       "0                       0  \n",
       "1                       0  \n",
       "2                       0  \n",
       "\n",
       "[3 rows x 30 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df['Name_Length_Category'] = all_df['Name_Length'].map(name_len_category)\n",
    "print(all_df['Name_Length_Category'].groupby(by = all_df['Name_Length_Category']).count().sort_values(ascending = False))\n",
    "\n",
    "le_fare = preprocessing.LabelEncoder()\n",
    "le_fare.fit(np.array(['Very_Short_Name', 'Short_Name', 'Medium_Name', 'Long_Name', 'Very_High_Fare']))\n",
    "all_df['Name_Length_Category'] = le_fare.transform(all_df['Name_Length_Category'])\n",
    "\n",
    "print(all_df[['Name_Length_Category', 'Survived']].corr())\n",
    "\n",
    "first_name_dummies_df = pd.get_dummies(all_df['Name_Length_Category'],\n",
    "                                prefix = all_df[['Name_Length_Category']].columns[0])\n",
    "all_df = pd.concat([all_df, first_name_dummies_df], axis = 1)\n",
    "all_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 Fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#filling the missing value using mean in Fare\n",
    "if (all_df['Fare'].isnull().sum() != 0):\n",
    "    all_df['Fare'] = all_df[['Fare']].fillna(all_df.groupby('Pclass').mean(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Name</th>\n",
       "      <th>Parch</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>...</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Officer</th>\n",
       "      <th>Title_Royalty</th>\n",
       "      <th>Name_Length</th>\n",
       "      <th>Name_Length_Category</th>\n",
       "      <th>Name_Length_Category_0</th>\n",
       "      <th>Name_Length_Category_1</th>\n",
       "      <th>Name_Length_Category_2</th>\n",
       "      <th>Name_Length_Category_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>7.25000</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>35.64165</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>7.92500</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>26.55000</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>8.05000</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age Cabin Embarked      Fare  \\\n",
       "0  22.0   NaN        S   7.25000   \n",
       "1  38.0   C85        C  35.64165   \n",
       "2  26.0   NaN        S   7.92500   \n",
       "3  35.0  C123        S  26.55000   \n",
       "4  35.0   NaN        S   8.05000   \n",
       "\n",
       "                                                Name  Parch  PassengerId  \\\n",
       "0                            Braund, Mr. Owen Harris      0            1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...      0            2   \n",
       "2                             Heikkinen, Miss. Laina      0            3   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)      0            4   \n",
       "4                           Allen, Mr. William Henry      0            5   \n",
       "\n",
       "   Pclass     Sex  SibSp           ...            Title_Mr Title_Mrs  \\\n",
       "0       3    male      1           ...                   1         0   \n",
       "1       1  female      1           ...                   0         1   \n",
       "2       3  female      0           ...                   0         0   \n",
       "3       1  female      1           ...                   0         1   \n",
       "4       3    male      0           ...                   1         0   \n",
       "\n",
       "   Title_Officer  Title_Royalty  Name_Length  Name_Length_Category  \\\n",
       "0              0              0           23                     2   \n",
       "1              0              0           51                     0   \n",
       "2              0              0           22                     2   \n",
       "3              0              0           44                     1   \n",
       "4              0              0           24                     2   \n",
       "\n",
       "   Name_Length_Category_0 Name_Length_Category_1  Name_Length_Category_2  \\\n",
       "0                       0                      0                       1   \n",
       "1                       1                      0                       0   \n",
       "2                       0                      0                       1   \n",
       "3                       0                      1                       0   \n",
       "4                       0                      0                       1   \n",
       "\n",
       "   Name_Length_Category_4  \n",
       "0                       0  \n",
       "1                       0  \n",
       "2                       0  \n",
       "3                       0  \n",
       "4                       0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#average fare for the tickets \n",
    "all_df['Group_Ticket'] = all_df['Fare'].groupby(by = all_df['Ticket']).transform('count')\n",
    "all_df['Fare'] = all_df['Fare']/all_df['Group_Ticket']\n",
    "all_df.drop(['Group_Ticket'], axis = 1, inplace = True)\n",
    "all_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1309.000000\n",
       "mean       15.017884\n",
       "std        13.529548\n",
       "min         3.170800\n",
       "25%         7.666667\n",
       "50%         8.300000\n",
       "75%        15.050000\n",
       "max       128.082300\n",
       "Name: Fare, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check if there are wired value, which is fare =0 \n",
    "if (sum(n == 0 for n in all_df.Fare.values.flatten()) > 0):\n",
    "    all_df.loc[all_df.Fare == 0, 'Fare'] = np.nan\n",
    "    all_df['Fare'] = all_df[['Fare']].fillna(all_df.groupby('Pclass').transform('mean'))\n",
    "\n",
    "all_df['Fare'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fare_Category\n",
      "1    745\n",
      "2    408\n",
      "0    112\n",
      "3     40\n",
      "4      4\n",
      "Name: Fare_Category, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#transform fare to fare_category \n",
    "all_df['Fare_Category'] = all_df['Fare'].map(fare_category)\n",
    "le_fare = preprocessing.LabelEncoder()\n",
    "le_fare.fit(np.array(['Very_Low_Fare', 'Low_Fare', 'Med_Fare', 'High_Fare', 'Very_High_Fare']))\n",
    "all_df['Fare_Category'] = le_fare.transform(all_df['Fare_Category'])\n",
    "\n",
    "fare_cat_dummies_df = pd.get_dummies(all_df['Fare_Category'],\n",
    "                                prefix = all_df[['Fare_Category']].columns[0])\n",
    "all_df = pd.concat([all_df, fare_cat_dummies_df], axis = 1)\n",
    "\n",
    "print(all_df['Fare_Category'].groupby(by = all_df['Fare_Category']).count().sort_values(ascending = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6 Pclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pclass\n",
      "1    34.661682\n",
      "2    11.663652\n",
      "3     7.379203\n",
      "Name: Fare, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(all_df['Fare'].groupby(by = all_df['Pclass']).mean())\n",
    "Pclass_1_mean_fare = all_df['Fare'].groupby(by = all_df['Pclass']).mean().get([1]).values[0]\n",
    "Pclass_2_mean_fare = all_df['Fare'].groupby(by = all_df['Pclass']).mean().get([2]).values[0]\n",
    "Pclass_3_mean_fare = all_df['Fare'].groupby(by = all_df['Pclass']).mean().get([3]).values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pclass_Fare_Category\n",
      "Pclass_3_High_Fare    432\n",
      "Pclass_3_Low_Fare     277\n",
      "Pclass_1_Low_Fare     209\n",
      "Pclass_2_High_Fare    155\n",
      "Pclass_2_Low_Fare     122\n",
      "Pclass_1_High_Fare    114\n",
      "Name: Pclass_Fare_Category, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#category variable from Pclass and Fare \n",
    "all_df['Pclass_Fare_Category'] = all_df.apply(pclass_fare_category, args=(Pclass_1_mean_fare, Pclass_2_mean_fare, Pclass_3_mean_fare), axis = 1)\n",
    "print(all_df['Pclass_Fare_Category'].groupby(by = all_df['Pclass_Fare_Category']).count().sort_values(ascending = False))\n",
    "\n",
    "le_fare = preprocessing.LabelEncoder()\n",
    "le_fare.fit(np.array(['Pclass_1_Low_Fare', 'Pclass_1_High_Fare', 'Pclass_2_Low_Fare', 'Pclass_2_High_Fare', 'Pclass_3_Low_Fare', 'Pclass_3_High_Fare']))\n",
    "all_df['Pclass_Fare_Category'] = le_fare.transform(all_df['Pclass_Fare_Category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pclass\n",
      "3     7.379203\n",
      "2    11.663652\n",
      "1    34.661682\n",
      "Name: Fare, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(all_df['Fare'].groupby(by = all_df['Pclass']).mean().sort_values(ascending = True))\n",
    "all_df['Pclass'].replace([1, 2, 3],[Pclass_1_mean_fare, Pclass_2_mean_fare, Pclass_3_mean_fare], inplace = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.7 Parch and SibSp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Family_Size\n",
      "1     790\n",
      "2     235\n",
      "3     159\n",
      "4      43\n",
      "6      25\n",
      "5      22\n",
      "7      16\n",
      "11     11\n",
      "8       8\n",
      "Name: Family_Size, dtype: int64\n",
      "Family_Size_Category\n",
      "Single          790\n",
      "Small_Family    394\n",
      "Large_Family    125\n",
      "Name: Family_Size_Category, dtype: int64\n",
      "Survived  Family_Size_Category\n",
      "0         Large_Family             94\n",
      "          Single                  627\n",
      "          Small_Family            246\n",
      "1         Large_Family             31\n",
      "          Single                  163\n",
      "          Small_Family            148\n",
      "Name: Survived, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "all_df['Family_Size'] = all_df['Parch'] + all_df['SibSp'] + 1\n",
    "print(all_df['Family_Size'].groupby(by = all_df['Family_Size']).count().sort_values(ascending = False))\n",
    "\n",
    "all_df['Family_Size_Category'] = all_df['Family_Size'].map(family_size_category)\n",
    "\n",
    "print(all_df['Family_Size_Category'].groupby(by = all_df['Family_Size_Category']).count().sort_values(ascending = False))\n",
    "print(all_df.groupby(['Survived', 'Family_Size_Category'])['Survived'].count())\n",
    "\n",
    "le_family = preprocessing.LabelEncoder()\n",
    "le_family.fit(np.array(['Single', 'Small_Family', 'Large_Family']))\n",
    "all_df['Family_Size_Category'] = le_family.transform(all_df['Family_Size_Category'])\n",
    "\n",
    "fam_size_cat_dummies_df = pd.get_dummies(all_df['Family_Size_Category'],\n",
    "                                prefix = all_df[['Family_Size_Category']].columns[0])\n",
    "all_df = pd.concat([all_df, fam_size_cat_dummies_df], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.8 Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title\n",
      "Master      5.482642\n",
      "Miss       21.795236\n",
      "Mr         32.244845\n",
      "Mrs        36.918129\n",
      "Royalty    41.166667\n",
      "Officer    46.272727\n",
      "Name: Age, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(all_df['Age'].groupby(by = all_df['Title']).mean().sort_values(ascending = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1309 entries, 0 to 417\n",
      "Data columns (total 27 columns):\n",
      "Age                       1046 non-null float64\n",
      "Parch                     1309 non-null int64\n",
      "SibSp                     1309 non-null int64\n",
      "Family_Size               1309 non-null int64\n",
      "Fare                      1309 non-null float64\n",
      "Title_Master              1309 non-null uint8\n",
      "Title_Miss                1309 non-null uint8\n",
      "Title_Mr                  1309 non-null uint8\n",
      "Title_Mrs                 1309 non-null uint8\n",
      "Title_Officer             1309 non-null uint8\n",
      "Title_Royalty             1309 non-null uint8\n",
      "Family_Size_Category_0    1309 non-null uint8\n",
      "Family_Size_Category_1    1309 non-null uint8\n",
      "Family_Size_Category_2    1309 non-null uint8\n",
      "Fare_Category_0           1309 non-null uint8\n",
      "Fare_Category_1           1309 non-null uint8\n",
      "Fare_Category_2           1309 non-null uint8\n",
      "Fare_Category_3           1309 non-null uint8\n",
      "Fare_Category_4           1309 non-null uint8\n",
      "Sex_female                1309 non-null uint8\n",
      "Sex_male                  1309 non-null uint8\n",
      "Pclass_7.37920274993      1309 non-null uint8\n",
      "Pclass_11.6636523985      1309 non-null uint8\n",
      "Pclass_34.6616822785      1309 non-null uint8\n",
      "Embarked_C                1309 non-null uint8\n",
      "Embarked_Q                1309 non-null uint8\n",
      "Embarked_S                1309 non-null uint8\n",
      "dtypes: float64(2), int64(3), uint8(22)\n",
      "memory usage: 89.5 KB\n"
     ]
    }
   ],
   "source": [
    "#flag the age null to 1 and not null in 0 \n",
    "all_df['Age_Null'] = all_df['Age'].apply(lambda x: 1 if(pd.notnull(x)) else 0)\n",
    "\n",
    "#prepare the dataframe for training \n",
    "missing_age_df = pd.DataFrame(all_df[['Age', 'Parch', 'Sex', 'SibSp', 'Family_Size', 'Family_Size_Category', 'Title', 'Fare', 'Fare_Category', 'Pclass', 'Embarked']])\n",
    "missing_age_df = pd.get_dummies(missing_age_df, columns = ['Title', 'Family_Size_Category', 'Fare_Category', 'Sex', 'Pclass', 'Embarked'])\n",
    "missing_age_df.shape\n",
    "missing_age_df.info()\n",
    "\n",
    "missing_age_train = missing_age_df[missing_age_df['Age'].notnull()]\n",
    "missing_age_test  = missing_age_df[missing_age_df['Age'].isnull()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=25)]: Done   5 out of  10 | elapsed:    1.3s remaining:    1.3s\n",
      "[Parallel(n_jobs=25)]: Done  10 out of  10 | elapsed:    1.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age feature Best GB Params: {'learning_rate': 0.01, 'max_depth': 3, 'max_features': 3, 'n_estimators': 2000}\n",
      "Age feature Best GB Score: -112.449390637\n",
      "GB Train Error for 'Age' Feature Regressor: -91.3369631585\n",
      "5     33.546420\n",
      "17    33.246757\n",
      "19    33.463058\n",
      "26    26.526942\n",
      "Name: Age_GB, dtype: float64\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Applications/anaconda/lib/python3.6/site-packages/scipy/linalg/basic.py:1018: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to 'gelss' driver.\n",
      "  warnings.warn(mesg, RuntimeWarning)\n",
      "/Applications/anaconda/lib/python3.6/site-packages/scipy/linalg/basic.py:1018: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to 'gelss' driver.\n",
      "  warnings.warn(mesg, RuntimeWarning)\n",
      "/Applications/anaconda/lib/python3.6/site-packages/scipy/linalg/basic.py:1018: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to 'gelss' driver.\n",
      "  warnings.warn(mesg, RuntimeWarning)\n",
      "/Applications/anaconda/lib/python3.6/site-packages/scipy/linalg/basic.py:1018: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to 'gelss' driver.\n",
      "  warnings.warn(mesg, RuntimeWarning)\n",
      "/Applications/anaconda/lib/python3.6/site-packages/scipy/linalg/basic.py:1018: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to 'gelss' driver.\n",
      "  warnings.warn(mesg, RuntimeWarning)\n",
      "/Applications/anaconda/lib/python3.6/site-packages/scipy/linalg/basic.py:1018: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to 'gelss' driver.\n",
      "  warnings.warn(mesg, RuntimeWarning)\n",
      "/Applications/anaconda/lib/python3.6/site-packages/scipy/linalg/basic.py:1018: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to 'gelss' driver.\n",
      "  warnings.warn(mesg, RuntimeWarning)\n",
      "/Applications/anaconda/lib/python3.6/site-packages/scipy/linalg/basic.py:1018: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to 'gelss' driver.\n",
      "  warnings.warn(mesg, RuntimeWarning)\n",
      "/Applications/anaconda/lib/python3.6/site-packages/scipy/linalg/basic.py:1018: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to 'gelss' driver.\n",
      "  warnings.warn(mesg, RuntimeWarning)\n",
      "/Applications/anaconda/lib/python3.6/site-packages/scipy/linalg/basic.py:1018: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to 'gelss' driver.\n",
      "  warnings.warn(mesg, RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age feature Best LR Params: {'fit_intercept': True, 'normalize': True}\n",
      "Age feature Best LR Score: -120.164070814\n",
      "LR Train Error for 'Age' Feature Regressor: -114.436752269\n",
      "5     34.50000\n",
      "17    33.59375\n",
      "19    31.12500\n",
      "26    26.84375\n",
      "Name: Age_LRF, dtype: float64\n",
      "5     34.023210\n",
      "17    33.420254\n",
      "19    32.294029\n",
      "26    26.685346\n",
      "Name: Age, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=25)]: Done   5 out of  10 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=25)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "/Applications/anaconda/lib/python3.6/site-packages/scipy/linalg/basic.py:1018: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to 'gelss' driver.\n",
      "  warnings.warn(mesg, RuntimeWarning)\n",
      "/Applications/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Applications/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Applications/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "#use the before function to fill the missing Age \n",
    "all_df.loc[(all_df.Age.isnull()), 'Age']= fill_missing_age(missing_age_train, missing_age_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title\n",
      "Master      5.438024\n",
      "Miss       21.694561\n",
      "Mr         32.148151\n",
      "Mrs        36.837474\n",
      "Royalty    41.166667\n",
      "Officer    46.465499\n",
      "Name: Age, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(all_df['Age'].groupby(by = all_df['Title']).mean().sort_values(ascending = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_df['Age_Category'] = all_df['Age'].map(age_group_cat)\n",
    "le_age = preprocessing.LabelEncoder()\n",
    "le_age.fit(np.array(['Baby', 'Toddler', 'Child', 'Teenager', 'Adult', 'Middle_Aged', 'Senior_Citizen', 'Old']))\n",
    "all_df['Age_Category'] = le_age.transform(all_df['Age_Category'])\n",
    "\n",
    "age_cat_dummies_df = pd.get_dummies(all_df['Age_Category'],\n",
    "                                prefix = all_df[['Age_Category']].columns[0])\n",
    "all_df = pd.concat([all_df, age_cat_dummies_df], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.9 Ticket & Cabin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1309, 1031)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df['Ticket_Letter'] = all_df['Ticket'].str.split().str[0]\n",
    "all_df['Ticket_Letter'] = all_df['Ticket_Letter'].apply(lambda x: np.NaN if x.isnumeric() else x)\n",
    "all_df['Ticket_Number'] = all_df['Ticket'].apply(lambda x: pd.to_numeric(x, errors='coerce'))\n",
    "all_df['Ticket_Number'].fillna(0, inplace = True)\n",
    "all_df = pd.get_dummies(all_df, columns = ['Ticket', 'Ticket_Letter'])\n",
    "all_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1309, 1224)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df['Cabin_Letter'] = all_df['Cabin'].apply(lambda x: str(x)[0]  if(pd.notnull(x)) else x)\n",
    "all_df = pd.get_dummies(all_df, columns = ['Cabin', 'Cabin_Letter'])\n",
    "all_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.10 Normalize Age and Fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>7.25000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>35.64165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>7.92500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>26.55000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>8.05000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age      Fare\n",
       "0  22.0   7.25000\n",
       "1  38.0  35.64165\n",
       "2  26.0   7.92500\n",
       "3  35.0  26.55000\n",
       "4  35.0   8.05000"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df[['Age', 'Fare']][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scale_age_fare = preprocessing.StandardScaler().fit(all_df[['Age', 'Fare']])\n",
    "all_df[['Age', 'Fare']] = scale_age_fare.transform(all_df[['Age', 'Fare']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age    -2.705586e-16\n",
       "Fare   -7.667239e-17\n",
       "dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df[['Age', 'Fare']].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.11 Drop columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_df.drop(['Name', 'PassengerId', 'Embarked', 'Sex', 'Title', 'Fare_Category', 'Family_Size_Category',\n",
    "               'Age_Category', 'Name_Length_Category'], \n",
    "              axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = all_df[:891]\n",
    "test_data = all_df[891:]\n",
    "\n",
    "titanic_train_data_X = train_data.drop(['Survived'], axis = 1)\n",
    "titanic_train_data_y = train_data['Survived']\n",
    "\n",
    "titanic_test_data_X = test_data.drop(['Survived'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 1214)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_test_data_X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Choose Top features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 2 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=25)]: Done  13 out of  20 | elapsed:   10.5s remaining:    5.6s\n",
      "[Parallel(n_jobs=25)]: Done  20 out of  20 | elapsed:   10.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top N Features Best RF Params: {'max_depth': 20, 'min_samples_split': 3, 'n_estimators': 500}\n",
      "Top N Features Best RF Score: 0.83164983165\n",
      "Top N Features RF Train Error: 0.94051627385\n",
      "Sample 25 Features from RF Classifier:\n",
      "8                 Sex_female\n",
      "9                   Sex_male\n",
      "12                  Title_Mr\n",
      "1                       Fare\n",
      "16               Name_Length\n",
      "0                        Age\n",
      "40             Ticket_Number\n",
      "11                Title_Miss\n",
      "26      Pclass_Fare_Category\n",
      "13                 Title_Mrs\n",
      "3                     Pclass\n",
      "27               Family_Size\n",
      "22           Fare_Category_1\n",
      "4                      SibSp\n",
      "30    Family_Size_Category_2\n",
      "2                      Parch\n",
      "18    Name_Length_Category_1\n",
      "7                 Embarked_S\n",
      "5                 Embarked_C\n",
      "17    Name_Length_Category_0\n",
      "19    Name_Length_Category_2\n",
      "29    Family_Size_Category_1\n",
      "20    Name_Length_Category_4\n",
      "23           Fare_Category_2\n",
      "32            Age_Category_0\n",
      "Name: feature, dtype: object\n",
      "Fitting 10 folds for each of 2 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=25)]: Done  13 out of  20 | elapsed:   19.7s remaining:   10.6s\n",
      "[Parallel(n_jobs=25)]: Done  20 out of  20 | elapsed:   19.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top N Features Best Ada Params: {'learning_rate': 0.5, 'n_estimators': 500}\n",
      "Top N Features Best Ada Score: 0.852974186308\n",
      "Top N Features Ada Train Error: 0.998877665544\n",
      "Sample 25 Features from Ada Classifier:\n",
      "40             Ticket_Number\n",
      "0                        Age\n",
      "1                       Fare\n",
      "9                   Sex_male\n",
      "8                 Sex_female\n",
      "16               Name_Length\n",
      "10              Title_Master\n",
      "145              Ticket_1601\n",
      "12                  Title_Mr\n",
      "1099           Cabin_C22 C26\n",
      "1012    Ticket_Letter_STON/O\n",
      "1016     Ticket_Letter_W./C.\n",
      "335              Ticket_2699\n",
      "828              Ticket_LINE\n",
      "27               Family_Size\n",
      "495            Ticket_347077\n",
      "1209          Cabin_Letter_D\n",
      "976       Ticket_Letter_A/5.\n",
      "7                 Embarked_S\n",
      "1208          Cabin_Letter_C\n",
      "989       Ticket_Letter_LINE\n",
      "772        Ticket_A/5. 10482\n",
      "110             Ticket_11668\n",
      "23           Fare_Category_2\n",
      "26      Pclass_Fare_Category\n",
      "Name: feature, dtype: object\n",
      "Fitting 10 folds for each of 2 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=25)]: Done  13 out of  20 | elapsed:    9.4s remaining:    5.0s\n",
      "[Parallel(n_jobs=25)]: Done  20 out of  20 | elapsed:    9.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top N Features Best ET Params: {'max_depth': 15, 'min_samples_split': 4, 'n_estimators': 500}\n",
      "Top N Features Best ET Score: 0.836139169473\n",
      "Top N Features ET Train Error: 0.920314253648\n",
      "Sample 25 Features from ET Classifier:\n",
      "12                    Title_Mr\n",
      "8                   Sex_female\n",
      "9                     Sex_male\n",
      "11                  Title_Miss\n",
      "3                       Pclass\n",
      "13                   Title_Mrs\n",
      "22             Fare_Category_1\n",
      "26        Pclass_Fare_Category\n",
      "30      Family_Size_Category_2\n",
      "16                 Name_Length\n",
      "17      Name_Length_Category_0\n",
      "1                         Fare\n",
      "23             Fare_Category_2\n",
      "18      Name_Length_Category_1\n",
      "29      Family_Size_Category_1\n",
      "27                 Family_Size\n",
      "7                   Embarked_S\n",
      "20      Name_Length_Category_4\n",
      "0                          Age\n",
      "28      Family_Size_Category_0\n",
      "4                        SibSp\n",
      "1207            Cabin_Letter_B\n",
      "5                   Embarked_C\n",
      "10                Title_Master\n",
      "1210            Cabin_Letter_E\n",
      "Name: feature, dtype: object\n",
      "Total Features: (1309, 1215)\n",
      "Picked Features: (286,)\n"
     ]
    }
   ],
   "source": [
    "features_to_pick = 200\n",
    "features_top_n = get_top_n_features(titanic_train_data_X, titanic_train_data_y, features_to_pick)\n",
    "\n",
    "print(\"Total Features: \" + str(all_df.shape))\n",
    "print(\"Picked Features: \" + str(features_top_n.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 286)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 0 to 890\n",
      "Columns: 286 entries, Sex_female to Ticket_S.O./P.P. 3\n",
      "dtypes: float64(4), int64(6), uint8(276)\n",
      "memory usage: 316.7 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "titanic_train_data_X = titanic_train_data_X[features_top_n]\n",
    "print(titanic_train_data_X.shape)\n",
    "print(titanic_train_data_X.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 418 entries, 0 to 417\n",
      "Columns: 286 entries, Sex_female to Ticket_S.O./P.P. 3\n",
      "dtypes: float64(4), int64(6), uint8(276)\n",
      "memory usage: 148.6 KB\n"
     ]
    }
   ],
   "source": [
    "titanic_test_data_X = titanic_test_data_X[features_top_n]\n",
    "titanic_test_data_X.shape\n",
    "titanic_test_data_X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "titanic_train_data = pd.concat([titanic_train_data_X, titanic_train_data_y], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 286)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_train_data_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 287)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "titanic_test_data_X.to_csv(\"data/topfeature_test.csv\", index=False)\n",
    "titanic_train_data.to_csv(\"data/topfeature_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
