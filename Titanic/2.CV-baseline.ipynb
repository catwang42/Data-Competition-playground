{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np #\n",
    "import pandas as pd \n",
    "import string\n",
    "import json\n",
    "from patsy import dmatrices\n",
    "from operator import itemgetter\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier, ExtraTreesClassifier,AdaBoostClassifier\n",
    "from sklearn.model_selection import cross_val_score \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.externals import joblib\n",
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df=pd.read_csv(\"data/train.csv\")\n",
    "test_df=pd.read_csv(\"data/test.csv\")\n",
    "seed= 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Set up basic funcitons "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#report grid search score for finding the best parameters \n",
    "def report(grid_scores, n_top=3):\n",
    "    top_scores = sorted(grid_scores, key=itemgetter(1), reverse=True)[:n_top]\n",
    "    for i, score in enumerate(top_scores):\n",
    "        print(\"Model with rank: {0}\".format(i + 1))\n",
    "        print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "              score.mean_validation_score,\n",
    "              np.std(score.cv_validation_scores)))\n",
    "        print(\"Parameters: {0}\".format(score.parameters))\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#substring function for finding titles in name columns \n",
    "def substrings_in_string(big_string, substrings):\n",
    "    for substring in substrings:\n",
    "        if big_string.find(substring) != -1:\n",
    "            return substring\n",
    "    print (big_string)\n",
    "    return np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encapsulate data cleaning and formating function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "enc=preprocessing.OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_and_munge_data(df):\n",
    "    df.Fare = df.Fare.map(lambda x: np.nan if x==0 else x)\n",
    "    #title list \n",
    "    title_list=['Mrs', 'Mr', 'Master', 'Miss', 'Major', 'Rev',\n",
    "                'Dr', 'Ms', 'Mlle','Col', 'Capt', 'Mme', 'Countess',\n",
    "                'Don', 'Jonkheer']\n",
    "    df['Title']=df['Name'].map(lambda x: substrings_in_string(x, title_list))\n",
    "    \n",
    "    #replace mapped title into different catogories \n",
    "    def replace_titles(x):\n",
    "        title=x['Title']\n",
    "        if title in ['Mr','Don', 'Major', 'Capt', 'Jonkheer', 'Rev', 'Col']:\n",
    "            return 'Mr'\n",
    "        elif title in ['Master']:\n",
    "            return 'Master'\n",
    "        elif title in ['Countess', 'Mme','Mrs']:\n",
    "            return 'Mrs'\n",
    "        elif title in ['Mlle', 'Ms','Miss']:\n",
    "            return 'Miss'\n",
    "        elif title =='Dr':\n",
    "            if x['Sex']=='Male':\n",
    "                return 'Mr'\n",
    "            else:\n",
    "                return 'Mrs'\n",
    "        elif title =='':\n",
    "            if x['Sex']=='Male':\n",
    "                return 'Master'\n",
    "            else:\n",
    "                return 'Miss'\n",
    "        else:\n",
    "            return title\n",
    "    \n",
    "    #new feature title \n",
    "    df['Title']=df.apply(replace_titles, axis=1)\n",
    "\n",
    "    #new feature family size\n",
    "    df['Family_Size']=df['SibSp']+df['Parch']\n",
    "    df['Family']=df['SibSp']*df['Parch']\n",
    "\n",
    "    #Handling missing value in Fare \n",
    "    #fill in missing fare with median value based on which class they are \n",
    "    df.loc[ (df.Fare.isnull())&(df.Pclass==1),'Fare'] =np.median(df[df['Pclass'] == 1]['Fare'].dropna())\n",
    "    df.loc[ (df.Fare.isnull())&(df.Pclass==2),'Fare'] =np.median( df[df['Pclass'] == 2]['Fare'].dropna())\n",
    "    df.loc[ (df.Fare.isnull())&(df.Pclass==3),'Fare'] = np.median(df[df['Pclass'] == 3]['Fare'].dropna())\n",
    "    \n",
    "    #mapping set to gender \n",
    "    df['Gender'] = df['Sex'].map( {'female': 0, 'male': 1} ).astype(int)\n",
    "    \n",
    "    #fill age with mean age base on different title \n",
    "    df['AgeFill']=df['Age']\n",
    "    mean_ages = np.zeros(4)\n",
    "    mean_ages[0]=np.average(df[df['Title'] == 'Miss']['Age'].dropna())\n",
    "    mean_ages[1]=np.average(df[df['Title'] == 'Mrs']['Age'].dropna())\n",
    "    mean_ages[2]=np.average(df[df['Title'] == 'Mr']['Age'].dropna())\n",
    "    mean_ages[3]=np.average(df[df['Title'] == 'Master']['Age'].dropna())\n",
    "    df.loc[ (df.Age.isnull()) & (df.Title == 'Miss') ,'AgeFill'] = mean_ages[0]\n",
    "    df.loc[ (df.Age.isnull()) & (df.Title == 'Mrs') ,'AgeFill'] = mean_ages[1]\n",
    "    df.loc[ (df.Age.isnull()) & (df.Title == 'Mr') ,'AgeFill'] = mean_ages[2]\n",
    "    df.loc[ (df.Age.isnull()) & (df.Title == 'Master') ,'AgeFill'] = mean_ages[3]\n",
    "    \n",
    "    #new feature age category \n",
    "    #better to transform continuse age value into different age bin \n",
    "    df['AgeCat']=df['AgeFill']\n",
    "    df.loc[ (df.AgeFill<=10) ,'AgeCat'] = 'child'\n",
    "    df.loc[ (df.AgeFill>60),'AgeCat'] = 'aged'\n",
    "    df.loc[ (df.AgeFill>10) & (df.AgeFill <=30) ,'AgeCat'] = 'adult'\n",
    "    df.loc[ (df.AgeFill>30) & (df.AgeFill <=60) ,'AgeCat'] = 'senior'\n",
    "\n",
    "    df.Embarked = df.Embarked.fillna('S')\n",
    "\n",
    "    df.loc[ df.Cabin.isnull()==True,'Cabin'] = 0.5\n",
    "    df.loc[ df.Cabin.isnull()==False,'Cabin'] = 1.5\n",
    "\n",
    "    df['Fare_Per_Person']=df['Fare']/(df['Family_Size']+1)\n",
    "\n",
    "    #new feature based on two highly relevant feature age and pclass \n",
    "    #create new features \n",
    "    df['AgeClass']=df['AgeFill']*df['Pclass']\n",
    "    df['ClassFare']=df['Pclass']*df['Fare_Per_Person']\n",
    "\n",
    "    \n",
    "    df['HighLow']=df['Pclass']\n",
    "    df.loc[ (df.Fare_Per_Person<8) ,'HighLow'] = 'Low'\n",
    "    df.loc[ (df.Fare_Per_Person>=8) ,'HighLow'] = 'High'\n",
    "\n",
    "    le.fit(df['Sex'] )\n",
    "    x_sex=le.transform(df['Sex'])\n",
    "    df['Sex']=x_sex.astype(np.float)\n",
    "\n",
    "    le.fit( df['Ticket'])\n",
    "    x_Ticket=le.transform( df['Ticket'])\n",
    "    df['Ticket']=x_Ticket.astype(np.float)\n",
    "\n",
    "    le.fit(df['Title'])\n",
    "    x_title=le.transform(df['Title'])\n",
    "    df['Title'] =x_title.astype(np.float)\n",
    "\n",
    "    le.fit(df['HighLow'])\n",
    "    x_hl=le.transform(df['HighLow'])\n",
    "    df['HighLow']=x_hl.astype(np.float)\n",
    "\n",
    "    le.fit(df['AgeCat'])\n",
    "    x_age=le.transform(df['AgeCat'])\n",
    "    df['AgeCat'] =x_age.astype(np.float)\n",
    "\n",
    "    le.fit(df['Embarked'])\n",
    "    x_emb=le.transform(df['Embarked'])\n",
    "    df['Embarked']=x_emb.astype(np.float)\n",
    "\n",
    "    df = df.drop(['PassengerId','Name','Age','Cabin'], axis=1) #remove Name,Age and PassengerId\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Cleaning data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df_feature = clean_and_munge_data(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891,) (891, 12)\n"
     ]
    }
   ],
   "source": [
    "formula_ml='Survived~Pclass+C(Title)+Sex+C(AgeCat)+Fare_Per_Person+Fare+Family_Size' \n",
    "\n",
    "y_train, x_train = dmatrices(formula_ml, data=train_df_feature, return_type='dataframe')\n",
    "y_train = np.asarray(y_train).ravel()\n",
    "print (y_train.shape,x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 13)\n"
     ]
    }
   ],
   "source": [
    "feature_train = pd.concat([x_train,y_train], axis=1)\n",
    "print(feature_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_train.to_csv(\"data/baseline_feature.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Split training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(x_train, y_train, test_size=0.2,random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_trian shape (712, 12)\n",
      "Y_train shape (712,)\n",
      "X_test shape (179, 12)\n",
      "Y_test shape (179,)\n"
     ]
    }
   ],
   "source": [
    "print(\"x_trian shape\",X_train.shape)\n",
    "print(\"Y_train shape\",Y_train.shape)\n",
    "print(\"X_test shape\",X_test.shape)\n",
    "print(\"Y_test shape\",Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Setup model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Regression Tree \n",
    "rf_clf=RandomForestClassifier(n_estimators=500, criterion='entropy', max_depth=5, min_samples_split=2,\n",
    "                           min_samples_leaf=1, max_features='auto',    bootstrap=False, oob_score=False, \n",
    "                           n_jobs=1, random_state=seed,verbose=0)\n",
    "\n",
    "\n",
    "#Ada Boosting use gridsearch find best parameters\n",
    "ada_clf = AdaBoostClassifier(random_state=seed, n_estimators=50,algorithm='SAMME',learning_rate=0.75 )\n",
    "\n",
    "#Extra Trees \n",
    "et_clf = ExtraTreesClassifier(n_estimators=500, max_features= 'sqrt',max_depth=8,criterion='entropy',\n",
    "                              n_jobs = 50,random_state =seed, verbose =0)\n",
    "\n",
    "\n",
    "#Gradient Boosting \n",
    "gbm_clf = GradientBoostingClassifier(learning_rate=0.1,n_estimators=50,min_samples_split=2,max_depth=5,\n",
    "                                     min_samples_leaf=5,max_features='sqrt',\n",
    "                                     loss='exponential',random_state=42,verbose=0)\n",
    "\n",
    "\n",
    "\n",
    "#SVC\n",
    "# svc_params = {\n",
    "#     'kernel' : ['linear'],\n",
    "#     'C' : [0.025],\n",
    "#     'gamma':[0.001, 0.01, 0.1]\n",
    "#     }\n",
    "# svc_clf=SVC()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n"
     ]
    }
   ],
   "source": [
    "%pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stratifiedCV = StratifiedShuffleSplit(n_splits = 10, test_size=0.2, random_state =0)\n",
    "param_grid = dict( )\n",
    "def grid_cv(clf,name):\n",
    "    grid_search = GridSearchCV(clf,verbose = 3, param_grid = param_grid,scoring ='accuracy', cv = stratifiedCV)\n",
    "    grid_search.fit(X_train,Y_train)\n",
    "    #print(name, \"Best Params:\" + str(grid_search.best_params_))\n",
    "    print(name, \"Best Score:\" + str(grid_search.best_score_))\n",
    "    print('-----grid search end------------')\n",
    "    print ('on all train set')\n",
    "    scores = cross_val_score(grid_search.best_estimator_, x_train, y_train,cv=3,scoring='accuracy')\n",
    "    print (scores.mean(),scores)\n",
    "    print ('on test set')\n",
    "    scores = cross_val_score(grid_search.best_estimator_, X_test, Y_test,cv=3,scoring='accuracy')\n",
    "    print (scores.mean(),scores)\n",
    "#     predictions\n",
    "#     predictions = grid_search.best_estimator_.predict(feature_test)\n",
    "    \n",
    "    return grid_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 5. Preparing testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(418, 17)\n"
     ]
    }
   ],
   "source": [
    "feature_test=clean_and_munge_data(test_df)\n",
    "print(feature_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(418, 12)\n"
     ]
    }
   ],
   "source": [
    "from patsy import dmatrix\n",
    "formula_ml='Pclass+C(Title)+Sex+C(AgeCat)+Fare_Per_Person+Fare+Family_Size' \n",
    "feature_test = dmatrix(formula_ml, data=feature_test, return_type='dataframe')\n",
    "print (feature_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_test.to_csv(\"data/baseline_feature_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Runing first level prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(418, 12)\n",
      "(891, 12)\n"
     ]
    }
   ],
   "source": [
    "print (feature_test.shape)\n",
    "print (x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891,)\n"
     ]
    }
   ],
   "source": [
    "print (y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1** Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.818182, total=   0.5s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.804196, total=   0.5s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    1.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.804196, total=   0.5s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.874126, total=   0.5s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.874126, total=   0.5s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.867133, total=   0.6s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.874126, total=   0.5s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.853147, total=   0.5s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.818182, total=   0.5s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.839161, total=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    5.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "randomForest Best Score:0.842657342657\n",
      "-----grid search end------------\n",
      "on all train set\n",
      "0.828282828283 [ 0.81144781  0.84511785  0.82828283]\n",
      "on test set\n",
      "0.798870056497 [ 0.75        0.85        0.79661017]\n"
     ]
    }
   ],
   "source": [
    "#Ramdom Forest \n",
    "rf_estimator = grid_cv(rf_clf, 'randomForest')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 1)\n",
      "(418, 1)\n"
     ]
    }
   ],
   "source": [
    "rf_train_predict = rf_estimator.predict(x_train).reshape(-1, 1)\n",
    "rf_predict = rf_estimator.predict(feature_test).reshape(-1, 1)\n",
    "print(rf_train_predict.shape)\n",
    "print(rf_predict.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 **Ada Boosting **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.818182, total=   0.6s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.825175, total=   0.6s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    1.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.832168, total=   0.6s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.853147, total=   0.6s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.839161, total=   0.6s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.860140, total=   0.6s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.860140, total=   0.6s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.846154, total=   0.6s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.790210, total=   0.6s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.825175, total=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    5.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoosting Best Score:0.834965034965\n",
      "-----grid search end------------\n",
      "on all train set\n",
      "0.817059483726 [ 0.8047138   0.82154882  0.82491582]\n",
      "on test set\n",
      "0.793502824859 [ 0.7         0.85        0.83050847]\n"
     ]
    }
   ],
   "source": [
    "ada_estimator = grid_cv(ada_clf, 'AdaBoosting')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 1)\n",
      "(418, 1)\n"
     ]
    }
   ],
   "source": [
    "ada_train_predict = ada_estimator.predict(x_train).reshape(-1, 1)\n",
    "ada_predict = ada_estimator.predict(feature_test).reshape(-1, 1)\n",
    "print(ada_train_predict.shape)\n",
    "print(ada_predict.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 **Gradient Boosting Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.832168, total=   0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.790210, total=   0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.804196, total=   0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.881119, total=   0.0s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.825175, total=   0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.881119, total=   0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.853147, total=   0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.832168, total=   0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.818182, total=   0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.846154, total=   0.0s\n",
      "GradientBoosting Best Score:0.836363636364\n",
      "-----grid search end------------\n",
      "on all train set\n",
      "0.829405162738 [ 0.81144781  0.83838384  0.83838384]\n",
      "on test set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.832580037665 [ 0.8         0.83333333  0.86440678]\n"
     ]
    }
   ],
   "source": [
    "gbm_estimator=grid_cv(gbm_clf,\"GradientBoosting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 1)\n",
      "(418, 1)\n"
     ]
    }
   ],
   "source": [
    "gbm_train_predict = gbm_estimator.predict(x_train).reshape(-1, 1)\n",
    "gbm_predict = gbm_estimator.predict(feature_test).reshape(-1, 1)\n",
    "print(gbm_train_predict.shape)\n",
    "print(gbm_predict.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Extra Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.811189, total=   0.7s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.818182, total=   0.6s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    1.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.790210, total=   0.6s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.881119, total=   0.6s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.846154, total=   0.6s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.804196, total=   0.6s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.853147, total=   0.6s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.832168, total=   0.7s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.811189, total=   0.6s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.867133, total=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    7.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTree Best Score:0.831468531469\n",
      "-----grid search end------------\n",
      "on all train set\n",
      "0.829405162738 [ 0.82491582  0.83164983  0.83164983]\n",
      "on test set\n",
      "0.838229755179 [ 0.8         0.83333333  0.88135593]\n"
     ]
    }
   ],
   "source": [
    "et_estimator = grid_cv(et_clf,\"ExtraTree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 1)\n",
      "(418, 1)\n"
     ]
    }
   ],
   "source": [
    "et_train_predict = et_estimator.predict(x_train).reshape(-1, 1)\n",
    "et_predict = et_estimator.predict(feature_test).reshape(-1, 1)\n",
    "print(et_train_predict.shape)\n",
    "print(et_predict.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Second level xgboost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_predict_change = ada_predict.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = np.concatenate((rf_train_predict, gbm_train_predict,ada_train_predict, et_train_predict), axis=1)\n",
    "x_test = np.concatenate(( rf_predict, gbm_predict,ada_predict, et_predict), axis=1)\n",
    "\n",
    "xgb_clf = xgb.XGBClassifier(n_estimators=2000,max_depth=4,min_child_weight=2,gamma=0.9,colsample_bytree=0.8,\n",
    "                              objective='binary:logistic', nthread=-1,scale_pos_weight=1).fit(x_train,y_train)\n",
    "xgb_prediction = xgb_clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "PassengerId = test_df['PassengerId']\n",
    "StackingSubmission = pd.DataFrame({ 'PassengerId': PassengerId,\n",
    "                            'Survived': xgb_prediction.astype(np.int32) })\n",
    "StackingSubmission.to_csv(\"submission/baselineCVSubmission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
